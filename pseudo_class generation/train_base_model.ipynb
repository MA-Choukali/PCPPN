{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RRv3I6vpu8AX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709231526536,"user_tz":-210,"elapsed":325051,"user":{"displayName":"MJ Lab","userId":"12526651074320095318"}},"outputId":"e75967a0-2a16-422d-85b1-031e85a30290"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/pseudo-class generation\n","Thu Feb 29 18:32:05 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd 'drive/My Drive/pseudo-class generation'\n","\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6177,"status":"ok","timestamp":1709231532707,"user":{"displayName":"MJ Lab","userId":"12526651074320095318"},"user_tz":-210},"id":"G_Dubluud9yv","outputId":"37f76569-aab5-47f0-fc48-ba58189df621"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting helpers\n","  Downloading helpers-0.2.0-py3-none-any.whl (2.3 kB)\n","Installing collected packages: helpers\n","Successfully installed helpers-0.2.0\n"]}],"source":["pip install helpers"]},{"cell_type":"markdown","metadata":{"id":"pdZLI01adDkM"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eX0c-hQz-jem"},"outputs":[],"source":["# License: BSD\n","# Author: Sasank Chilamkurthy\n","\n","from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","cudnn.benchmark = True\n","plt.ion()   # interactive mode\n","\n","from helpers import makedir\n","from log import create_logger\n","from preprocess import mean, std, preprocess_input_function"]},{"cell_type":"markdown","metadata":{"id":"WTpoKB1LVIaG"},"source":["# Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTmJA_xeUuMO"},"outputs":[],"source":["# Models can be choosed from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","n_fold = '1'\n","model_name = \"resnet\"         # Resnet18\n","target_test_accu = 0.80\n","\n","img_size = 300  # 224\n","num_epochs = 100\n","num_classes = 2\n","\n","BATCH_SIZE = 80\n","\n","train_batch_size = BATCH_SIZE\n","test_batch_size = BATCH_SIZE\n","train_push_batch_size = BATCH_SIZE\n","model_dir = './saved_models/' + model_name + '_fold'+ n_fold + '/'\n","makedir(model_dir)"]},{"cell_type":"markdown","metadata":{"id":"vGCS86sdVLrW"},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57110,"status":"ok","timestamp":1709231593653,"user":{"displayName":"MJ Lab","userId":"12526651074320095318"},"user_tz":-210},"id":"49truZE4BoyM","outputId":"5b065b69-246a-43ee-8547-87e7f82f857b"},"outputs":[{"output_type":"stream","name":"stdout","text":["training set size: 10595\n","push set size: 995\n","test set size: 605\n","batch size: 80\n"]}],"source":["magnification = '40x'\n","train_test = '/test'\n","fold = 'revised_fold' + n_fold + '_' + magnification\n","data_path = './dataset/' + fold + '/'\n","train_dir = data_path + 'train_push_balanced/train_augmented/'\n","test_dir = data_path + 'test/'\n","train_push_dir = data_path + 'train/'\n","\n","log, logclose = create_logger(log_filename=os.path.join(model_dir, 'train.log'))\n","\n","# load the data\n","normalize = transforms.Normalize(mean=mean,\n","                                 std=std)\n","\n","# all datasets\n","# train set\n","train_dataset_0 = datasets.ImageFolder(\n","    train_dir,\n","    transforms.Compose([\n","        transforms.Resize(size=(img_size, img_size)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","\n","#train_loader_0 = torch.utils.data.DataLoader(\n","#    train_dataset_0, batch_size=train_batch_size, shuffle=True,\n","#    num_workers=4, pin_memory=False)\n","\n","# push set\n","train_push_dataset = datasets.ImageFolder(\n","    train_push_dir,\n","    transforms.Compose([\n","        transforms.Resize(size=(img_size, img_size)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","train_push_loader = torch.utils.data.DataLoader(\n","    train_push_dataset, batch_size=train_push_batch_size, shuffle=False,\n","    num_workers=4, pin_memory=False)\n","\n","train_dataset = train_dataset_0 + train_push_dataset\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True,\n","    num_workers=4, pin_memory=False)\n","\n","# test set\n","test_dataset = datasets.ImageFolder(\n","    test_dir,\n","    transforms.Compose([\n","        transforms.Resize(size=(img_size, img_size)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ]))\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=test_batch_size, shuffle=False,\n","    num_workers=4, pin_memory=False)\n","\n","# we should look into distributed sampler more carefully at torch.utils.data.distributed.DistributedSampler(train_dataset)\n","\n","#log('training_0 set size: {0}'.format(len(train_loader_0.dataset)))\n","log('training set size: {0}'.format(len(train_loader.dataset)))\n","log('push set size: {0}'.format(len(train_push_loader.dataset)))\n","log('test set size: {0}'.format(len(test_loader.dataset)))\n","log('batch size: {0}'.format(train_batch_size))\n","\n","dataloaders = {'train' : train_loader , 'val': test_loader }\n","dataset_sizes = {'train' : len(train_loader) , 'val': len(test_loader) }"]},{"cell_type":"markdown","metadata":{"id":"Q4BZQaiqNtMf"},"source":[]},{"cell_type":"markdown","metadata":{"id":"_ZlRBEbDN2Lm"},"source":["# Model initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bm943E9DNyNH"},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","    if feature_extracting == False:\n","        for param in model.parameters():\n","            param.requires_grad = True\n","\n","def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet\":\n","        \"\"\" Resnet18\n","        \"\"\"\n","        model_ft = models.resnet18(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = img_size\n","        #model_ft.fc = nn.Identity()\n","\n","\n","    elif model_name == \"alexnet\":\n","        \"\"\" Alexnet\n","        \"\"\"\n","        model_ft = models.alexnet(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = img_size\n","\n","    elif model_name == \"vgg\":\n","        \"\"\" VGG11_bn\n","        \"\"\"\n","        model_ft = models.vgg19(pretrained = use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = img_size\n","\n","    elif model_name == \"squeezenet\":\n","        \"\"\" Squeezenet\n","        \"\"\"\n","        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n","        model_ft.num_classes = num_classes\n","        input_size = img_size\n","\n","    elif model_name == \"densenet\":\n","        \"\"\" Densenet\n","        \"\"\"\n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","        #model_ft.classifier = nn.Identity()\n","        input_size = img_size\n","\n","    elif model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained = use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        # Handle the auxilary net\n","        num_ftrs = model_ft.AuxLogits.fc.in_features\n","        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n","        # model_ft.fc = nn.Identity()\n","        # model_ft.AuxLogits.fc =  nn.Identity()\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft"]},{"cell_type":"markdown","metadata":{"id":"EBJfdhgbKqMD"},"source":["# training function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xQRs446_Q7d"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, model_name = \"inception\"):\n","    since = time.time()\n","\n","    if model_name == \"inception\":\n","       is_inception = True\n","    else:\n","       is_inception=False\n","\n","\n","    train_acc = []\n","    val_acc = []\n","    #train_loss = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 +  0.4 * loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","            if phase == 'train':\n","               train_acc.append(epoch_acc)\n","               #train_loss.append(epoch_loss)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","            if phase == 'val':\n","                val_acc.append(epoch_acc)\n","                if best_acc > target_test_accu:\n","                    filepath = model_dir + str(epoch) + '_' +str(best_acc) + \".pt\"\n","                    torch.save(model.state_dict(), filepath)\n","\n","        print()\n","\n","    torch.save(train_acc, 'Train_log')\n","    torch.save(val_acc, 'Test_log')\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    return model, train_acc, val_acc\n","\n","#model = TheModelClass(*args, **kwargs)\n","#model.load_state_dict(torch.load(PATH))\n","\n","def test(model , test_loader, num_Test_data, criterion):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    All_preds = []\n","    All_labels = []\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels =  labels.to(device)\n","            preds = model(images)\n","            loss = criterion(preds , labels)\n","            test_loss += loss\n","            preds = torch.argmax(preds , dim = 1)\n","            All_preds.append(preds.cpu().numpy())\n","            All_labels.append(labels.cpu().numpy())\n","\n","            correct += (preds == labels).float().sum()\n","        print(labels)\n","        print(preds)\n","        accuracy = correct / num_Test_data\n","        epoch_loss = test_loss / num_Test_data\n","        print(\"   loss:%.2f\" %epoch_loss.item() , \"  Acc:%.2f\" %accuracy.item() )\n","        All_labels = np.concatenate( All_labels, axis=0 )\n","        All_preds = np.concatenate( All_preds, axis=0 )\n","    return All_labels ,All_preds"]},{"cell_type":"markdown","metadata":{"id":"nmu95Z8kQBpC"},"source":["# Cunstruct the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IGZtyTK5s2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709231593654,"user_tz":-210,"elapsed":10,"user":{"displayName":"MJ Lab","userId":"12526651074320095318"}},"outputId":"47295362-78dd-46ef-9165-d2581cc440f8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"]}],"source":["criterion = nn.CrossEntropyLoss()\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = False\n","\n","# Initialize the model for this run\n","modelA = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","# Send the model to GPU\n","modelA = modelA.to(device)\n","optimizerA = optim.Adam(modelA.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2-WP_Y8pCp0"},"outputs":[],"source":["# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = modelA.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in modelA.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in modelA.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","## Find total parameters and trainable parameters\n","#total_params = sum(p.numel() for p in modelA.parameters())\n","#print(f'{total_params:,} total parameters.')\n","#total_trainable_params = sum(\n","#    p.numel() for p in modelA.parameters() if p.requires_grad)\n","#print(f'{total_trainable_params:,} training parameters.')"]},{"cell_type":"markdown","metadata":{"id":"9KsUIM9uVu4P"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBRwwL0WApCh"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_dataset = test_dataset\n","val_loader = torch.utils.data.DataLoader(dataset = val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","dataloaders_dict = {'train' : train_loader , 'val': val_loader }\n","# Train and evaluate\n","modelA, train_acc, val_acc = train_model(modelA, dataloaders_dict, criterion, optimizerA, num_epochs = num_epochs , model_name = model_name)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rHWt7kQc2dEy"},"source":["# Compute Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403719,"status":"ok","timestamp":1709231997368,"user":{"displayName":"MJ Lab","userId":"12526651074320095318"},"user_tz":-210},"id":"meylzVi9QPIy","outputId":"1d794a09-6d99-4a82-bd4a-27b1a4ca06ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n","       device='cuda:0')\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       device='cuda:0')\n","   loss:0.01   Acc:0.81\n","[[132 107]\n"," [  5 361]]\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.55      0.70       239\n","           1       0.77      0.99      0.87       366\n","\n","    accuracy                           0.81       605\n","   macro avg       0.87      0.77      0.78       605\n","weighted avg       0.85      0.81      0.80       605\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","## Select trained model at epoch with best test/val accuracy as feature extractor\n","filepath2 = model_dir + \"50_tensor(0.8793, device=_cuda_0_, dtype=torch.float64).pt\"\n","model = modelA\n","model.load_state_dict(torch.load(filepath2))\n","\n","Test_data = test_dataset\n","num_Test_data = len(Test_data)\n","test_loader = torch.utils.data.DataLoader(dataset = Test_data , batch_size=BATCH_SIZE, shuffle=True) # + val_dataset\n","All_labels ,All_preds = test(model, test_loader, num_Test_data, criterion)\n","print(confusion_matrix(All_labels ,All_preds ))\n","print(classification_report(All_labels ,All_preds ))"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN7j13F4e6ZH61NSMOQC+lU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}